---
title: "Peatland SIP"
subtitle: "03 Filtering out rare taxa"
description: "V1.6"   
author: "Roey Angel"
email: "roey.angel@bc.cas.cz"
date: "`r Sys.Date()`"
bibliography: references.bib
link-citations: true
csl: fems-microbiology-ecology.csl
always_allow_html: true
output:
  rmarkdown::github_document:
    toc: true
    toc_depth: 5
    number_sections: false
    dev: "png"
    df_print: "kable"
    keep_html: true
editor_options: 
  chunk_output_type: console
---

```{r setup}
.libPaths(c("/home/nwezejus/R/x86_64-pc-linux-gnu-library/4.5.1", .libPaths()))
```

```{r}
required_packages <- c("tidyverse", "vsn", "extrafont", "phyloseq", "vegan", "Biostrings", "svglite", "see", "easystats", "kableExtra", "magrittr", "scales", "speedyseq")

for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    message(paste("Installing", pkg))
    if (pkg %in% rownames(installed.packages()) == FALSE) {
      if (pkg %in% BiocManager::available()) {
        BiocManager::install(pkg)
      } else {
        install.packages(pkg)
      }
    }
  }
}

```


```{r}
#| label = "libraries",
#| include = F
# .libPaths(c('~/R/x86_64-pc-linux-gnu-library/4.5.1', .libPaths())) # Uncomment if you have no write access to R path
library(extrafont) # Tools for using fonts, CRAN v0.17 
library(tidyverse) # Easily Install and Load the 'Tidyverse', CRAN v1.3.0 
library(scales) # Scale Functions for Visualization, CRAN v1.1.1 # Scale Functions for Visualization, CRAN v1.1.1 
library(magrittr) # A Forward-Pipe Operator for R, CRAN v2.0.1 
library(phyloseq) # Handling and analysis of high-throughput microbiome census data, Bioconductor v1.32.0 
library(speedyseq) # Faster implementations of phyloseq functions, [github::mikemc/speedyseq] v0.5.3.9001 
library(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax, CRAN v1.3.1 
library(vegan) # Community Ecology Package, CRAN v2.5-7 
library(Biostrings) # Efficient manipulation of biological strings, Bioconductor v2.56.0
library(svglite) # An 'SVG' Graphics Device, CRAN v1.2.3.2
library(see) # Visualisation Toolbox for 'easystats' and Extra Geoms, Themes and Color Palettes for 'ggplot2', CRAN v0.6.1 
library(easystats)
library(vsn)
library(ggplot2)
library(tidyverse)
```

```{r}
#| label = "style settings",
#| echo = F,
#| message = F,
#| warning = F,
#| results = "asis",
#| cache = T
options(width = 90, knitr.table.format = "html") 
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  dev = c("svglite", "ragg_png"),
  dev.args = list(svglite = list(bg = 'white', fix_text_size = FALSE), ragg_png = list(bg = 'white')),
  dpi = 300,
#  fig.width = 12,
#  fig.height = 8,
  cache.path = "03_Filter_taxa_cache/",
  fig.path = "03_Filter_taxa_figures/"
)
f_name <- "DejaVu Sans" #sub("\\s//", "", f_name)
f_size <- 12
font_import(pattern = "DejaVuSans\\.", prompt = FALSE)
loadfonts() # registers fonts
theme_set(theme_bw(base_size = f_size, base_family = f_name))
```

```{r}
#| label = "functions",
#| include = F
#' phyloseq_merge_samples
#' Like phyloseq::merge_samples() but retains chr and fct information in sample_data()
#'
#' Merge/agglomerate the sample indices of a phyloseq object according to a categorical variable contained in a sample_data or a provided factor.
#' Unlike merge_samples() this function will only apply a `mean` to numeric variables in `samples_data()` and will retain all unique values of any non-numeric variable.
#' chr or fct variables with non-identical levels in the marged samples are combined to a comma-separated string.
#'
#' @author Roey Angel (https://github.com/roey-angel)
#' @usage phyloseq_merge_samples(Ps_obj, grouping_name = "Description")
#' @param ps (Required). A phyloseq object that has sample indices.
#'
#' @param grouping_name (Required). A single character string matching a variable name in
#'  the corresponding sample_data of \code{ps}.
#'
#' @param fun (Optional). The function that will be used to merge the values that
#'  correspond to the same group for each variable.
#'  Note that this is (currently) ignored for the otu_table, where the equivalent
#'  function is \code{\link[base]{sum}}, but evaluated via \code{\link[base]{rowsum}}
#'  for efficiency.
#'
#' @return A merged phyloseq object with its sample indices merged according to the factor indicated by the \code{grouping_name} argument.
#'
#' @seealso \code{\link{phyloseq::merge_samples}}
#'
#' @export

phyloseq_merge_samples <- function(ps = Ps_obj, grouping_name = "Description", fun = "mean") {
  require(dplyr)
  require(purrr)
  require(phyloseq)

  if (taxa_are_rows(ps)) {ps <- t(ps)} # needs to be in sample-by-species orientation
  SD2merge <- as_tibble(sample_data(ps)) # grab sample_data
  org_col_names <- colnames(SD2merge) # retain original sample_data variable order
  grouping_col <- select(SD2merge, group = all_of(grouping_name)) # grab grouping var
  # grap factor variables
  SD2merge %>%
    select_if(is.factor) %>%
    colnames() ->
    fct_vars

  # merge the OTU table
  ps %>%
    otu_table() %>%
    as(., "matrix") %>%
    rowsum(., as_vector(grouping_col)) %>%
    # convert back to otu_table, and return
    otu_table(., taxa_are_rows = FALSE) ->
    merged_OTU_table

  # ps %>% # generalised form but very slow
  #   otu_table() %>%
  #   as(., "matrix") %>%
  #   as.tibble() %>%
  #   group_by(as_vector(grouping_col)) %>%
  #   summarise_all(., fun)

  # merge numeric
  SD2merge %>%
    select_if(is.numeric) %>%
    bind_cols(grouping_col, .) %>%
    group_by(group) %>%
    summarise_all(., fun, na.rm = TRUE) ->
    numeric_cols

  # merge other
  SD2merge %>%
    select_if(negate(is.numeric)) %>%
    bind_cols(grouping_col, .) %>%
    group_by(group) %>%
    summarise_all(list(~paste(unique(.), collapse = ",")))  ->
    other_cols

  # join merged numeric and other columns
  full_join(numeric_cols, other_cols, by = "group") %>%
    select(-group) %>%
    select(all_of(org_col_names)) %>% # order columns like they were
    mutate_at(fct_vars, ~(factor(.))) %>% # return factor type to fct vars
    mutate(torownames = !!sym(grouping_name)) %>% 
    column_to_rownames(var = "torownames") ->
    merged_SD

  # build and return a phyloseq object
  return(phyloseq(otu_table(merged_OTU_table),
                  sample_data(merged_SD),
                  tax_table(ps)))
}

#' plot_lib_dist
#' Plot distribution of amplicon library sizes as a histogram
#'
#' @param Ps_obj (Required) A phyloseq object
#'
#' @author Roey Angel (https://github.com/roey-angel)
#' @return A ggplot object
#' @usage plot_lib_dist(Ps_obj)
#' @export

plot_lib_dist <- function(Ps_obj){
  require(ggplot2)
  require(scales)
  data.frame(sum = sample_sums(Ps_obj)) %>%
  ggplot(aes(x = sum)) +
    geom_histogram(color = "black",
                   fill = "indianred") +
    theme(panel.grid.minor = element_blank()) +
    labs(x = "Library size" , y = "Sample count") ->
    lib_dist_plot
  return(lib_dist_plot)
}

#' plot_read_dist
#' Plot the distribution of ASV abundances
#'
#' @param Ps_obj (Required) A phyloseq object
#'
#' @param b.width (Optional) binwidth option in geom_freqpoly
#'
#' @author Roey Angel (https://github.com/roey-angel)
#' @return A ggplot object
#' @usage plot_read_dist(Ps_obj, b.width = 10)
#' @export

plot_read_dist <- function(Ps_obj, b.width = 10){
  require(ggplot2)
  require(scales)

  as(otu_table(Ps_obj), "matrix") %>%
    t() %>%
    as_tibble() %>%
    gather(key = sample, value = abundance) %>%
    ggplot(aes(abundance)) +
    # geom_histogram(binwidth = 1000) +
    geom_freqpoly(binwidth = b.width) +
    scale_y_log10(
      breaks = trans_breaks("log10", function(x)
        10 ^ x),
      labels = trans_format("log10", math_format(10 ^ .x))
    ) ->
    ASV_dist_plot
  return(ASV_dist_plot)
}

#' plot_lib_size
#' Plot distribution of amplicon library sizes as a faceted bar graph
#'
#' @param Ps_obj (Required) A phyloseq object
#'
#' @param x  (Required) X-axis variable (must be a sample_data(Ps_obj) column)
#'
#' @param fill (Required) Fill colour variable (must be a sample_data(Ps_obj) column)
#'
#' @param facet1 (Optional) Rows facet variable (must be a sample_data(Ps_obj) column)
#'
#' @param facet2 (Optional) Columns variable (must be a sample_data(Ps_obj) column)
#'
#' @author Roey Angel (https://github.com/roey-angel)
#' @return A ggplot object
#' @usage plot_lib_size(Ps_obj, x, fill, facet)
#' @export

plot_lib_size <- function(Ps_obj, x, fill, facet1 = ".", facet2 = "."){
  require(ggplot2)
  require(scales)
  Library.size <- rowSums(otu_table(Ps_obj))
  ggplot(sample_data(Ps_obj),
         aes(x = !!sym(x), y = Library.size, fill = !!sym(fill))) +
    geom_bar(stat = "identity",
             position = "dodge",
             color = "black") +
    scale_y_log10(
      breaks = trans_breaks("log10", function(x)
        10 ^ x),
      labels = trans_format("log10", math_format(10 ^ .x))
    ) +
    theme(panel.grid.minor = element_blank()) +
    scale_fill_brewer(type = 'qual', palette = 'Set2', direction = -1) +
    facet_grid(as.formula(paste(facet1, facet2, sep = "~"))) +
    ylab("Library size") ->
    lib_dist_plot
  return(lib_dist_plot)
}

#' plot_mean_SD
#' A wrapper for vsn::meanSdPlot for phyloseq objects
#'
#' @param Ps_obj (Required) A phyloseq object
#'
#' @param b.width (Optional) binwidth option in geom_freqpoly
#'
#' @author Roey Angel (https://github.com/roey-angel)
#' @return A ggplot object
#' @usage plot_mean_SD(Ps_obj, x, fill, facet)
#' @export

plot_mean_SD <- function(Ps_obj){
  require(phyloseq)
  require(ggplot2)
  require(vsn)
  if (taxa_are_rows(Ps_obj)) {Ps_obj <- t(Ps_obj)} # transpose if taxa are rows
  notAllZero <- (rowSums(t(otu_table(Ps_obj))) > 0)
  meanSdPlot(as.matrix(log2(t(otu_table(Ps_obj))[notAllZero, ] + 1)))
}

```

## Filter out rare taxa and those not classified as bacteria or archaea

### Setting general parameters:
```{r}
#| label = "general parameters",
#| cache = T
set.seed(1000)
prev_thresh <- 0.05 # remove ASVs with prevalence less than that
data_path <- "./DADA2_pseudo/"
# Metadata_table <- "./AMetadata_decontam.csv"
# Seq_table <- "DADA2.seqtab_nochim_decontam.tsv"
# Tax_table <- "DADA2.taxa_silva.tsv"
Seq_file <- "DADA2_reps_decontam.fa"
Proj_name <- "Peatland_SIP"
Ps_file <- paste0(Proj_name, "_decontam.Rds")
Var1 = "Fraction_no." # e.g sampling point / replicate
Var2 = "Treatment" # e.g. a treatment or a manipulation
Var3 = "Ammo" # e.g. a treatment/manipulation or an important covariant
Var4 = "Label" # e.g. an important covariant
```

### Read phyloseq object
Also remove controls
```{r}
#| label = "load data",
#| cache = T
readRDS(paste0(data_path, Ps_file)) %>% 
  subset_samples(., !is.na(Headspace) & !is.na(Treatment)) -> 
  Ps_obj_SIP 
  
sample_data(Ps_obj_SIP) %<>%
  as("data.frame") %>%
  mutate(across(c(
    !!sym(Var2),
    !!sym(Var3),
    !!sym(Var4)
  ), ~ factor(.)))
```

Combine repeated runs
```{r}
#| label = "combine repeats",
#| cach = T
#sample_data(Ps_obj_SIP) %<>% 
#  as("data.frame") %>% 
#  rownames_to_column() %>% 
#  mutate(Identifier = paste(sample_ID, Label..13C., Day, Fraction.no., Replicate, Sample.no., 
#                            sep = "_")) %>% 
#  column_to_rownames("rowname") 
  
# phyloseq_merge_samples(Ps_obj_SIP, "Identifier") %>% 

Ps_obj_SIP %>%
 filter_taxa(., function(x) sum(x) > 0, TRUE) ->
Ps_obj_SIP 

# Compute lib sizes
sample_data(Ps_obj_SIP)$Library.size <- rowSums(otu_table(Ps_obj_SIP))
```

### Exploring dataset features
First let us look at the count data distribution
```{r}
#| label = "plot abundance",
#| cache = T
plot_lib_size(Ps_obj_SIP, x = Var1, fill = Var2, facet1 = Var4, facet2 = Var2)
```

I will test now the effect of library size and all other experimental factors on the community composition and also plot 
```{r}
#| label = "mod abundance 1",
#| cache = T

frml <- as.formula(paste(
  "vegdist(otu_table(Ps_obj_SIP), method = 'bray')",
  paste(Var2, Var3, sep = " * "),
  sep = " ~ "
))

(mod1 <- adonis2(frml, data = get_variable(Ps_obj_SIP), permutations = 999))

plot_lib_dist(Ps_obj_SIP)
plot_read_dist(Ps_obj_SIP)
plot_mean_SD(Ps_obj_SIP)
```

Modelling library size shows a significant effect of read depth on the community structure, but explaining only `r percent(mod1$R2[3])` of the variance.
The reads histogram shows as expected a highly sparse and skewed sequence matrix.
The mean vs SD also shows as expected large dependency of SD on the mean reads of a sequence across all samples.

#### Taxa-based filtering 
Now let us look at the taxonomic distribution
```{r}
#| label = "taxa table",
#| cache = T
table(tax_table(Ps_obj_SIP)[, "Kingdom"], exclude = NULL)
table(tax_table(Ps_obj_SIP)[, "Class"], exclude = NULL)
# table(tax_table(Ps_obj)[, "Family"], exclude = NULL)
```
Accordingly, we will remove some taxa which are obvious artefacts or those which aren't bacteria or archaea
```{r}
#| label = "remove unwated taxa",
#| cache = T
kingdoms2remove <- c("", "Eukaryota", "Unclassified")
orders2remove <- c("Chloroplast")
families2remove <- c("Mitochondria")

Ps_obj_kingdoms <- tax_glom(Ps_obj_SIP, "Kingdom")
Ps_obj_orders <- tax_glom(Ps_obj_SIP, "Order")
Ps_obj_families <- tax_glom(Ps_obj_SIP, "Family")

Ps_obj_tax_filt <- subset_taxa(Ps_obj_SIP, !is.na(Phylum) &
                        !Kingdom %in% kingdoms2remove &
                      !Order %in% orders2remove &
                      !Family %in% families2remove)
```

```{r}
#| label = "summarised pruned taxa",
#| cache = T
Summary_pruned <- tibble(
  Level = c("Kingdom", "Order", "Family"),
  ASVs.removed = c(
    table(tax_table(Ps_obj_SIP)[, "Kingdom"], exclude = NULL) %>% as.data.frame() %>% .[.$Var1 == "" | .$Var1 == "Eukaryota" | .$Var1 == "Unclassified", 2] %>% sum(),
    table(tax_table(Ps_obj_SIP)[, "Order"], exclude = NULL) %>% as.data.frame() %>% .[.$Var1 == "Chloroplast", 2] %>% sum(),
    table(tax_table(Ps_obj_SIP)[, "Family"], exclude = NULL) %>% as.data.frame() %>% .[.$Var1 == "Mitochondria", 2] %>% sum()
                     ),
  Seqs.removed = c(
    psmelt(Ps_obj_kingdoms) %>%
      group_by(Kingdom) %>%
      filter(Kingdom == "" |
               Kingdom == "Eukaryota" | Kingdom == "Unclassified") %>%
      summarise(sum = sum(Abundance)) %>% .$sum %>% sum(),
    psmelt(Ps_obj_orders) %>%
      group_by(Order) %>%
      filter(Order == orders2remove) %>%
      summarise(sum = sum(Abundance)) %>% .$sum %>% sum(),
    psmelt(Ps_obj_families) %>%
      group_by(Family) %>%
      filter(Family == families2remove) %>%
      summarise(sum = sum(Abundance)) %>% .$sum %>% sum()
    )
  )

Summary_pruned %>% 
  kable(., digits = c(0, 1, 0)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

Removed `r percent(Summary_pruned$Seqs.removed[Summary_pruned$Level == "Order"] / sum(sample_sums(Ps_obj_SIP)), accuracy = 0.0001)` of the sequences.

Now let's explore the prevalence of different taxa in the database.
Prevalence is the number of samples in which a taxa appears at least once. So "Mean prevalence" refers to in how many samples does a sequence belonging to the phylum appears on average, and "Sum prevalence" is the sum of all samples where any sequence from the taxon appears.
```{r}
#| label = "explore revalence",
#| cache = T
prevdf <- apply(X = otu_table(Ps_obj_tax_filt),
                 MARGIN = ifelse(taxa_are_rows(Ps_obj_tax_filt), yes = 1, no = 2),
                 FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf <- data.frame(Prevalence = prevdf,
                      TotalAbundance = taxa_sums(Ps_obj_tax_filt),
                      tax_table(Ps_obj_tax_filt))

prevdf %>%
  group_by(Phylum) %>%
  summarise(`Mean prevalence` = mean(Prevalence),
            `Sum prevalence` = sum(Prevalence)) ->
  Prevalence_phylum_summary

Prevalence_phylum_summary %>% 
  kable(., digits = c(0, 1, 0)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

prevdf %>%
  group_by(Order) %>%
  summarise(`Mean prevalence` = mean(Prevalence),
            `Sum prevalence` = sum(Prevalence)) ->
  Prevalence_order_summary

Prevalence_order_summary %>% 
  kable(., digits = c(0, 1, 0)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

Based on that I'll remove all orders with a sum prevalence of under 5% (`r 0.05 * nsamples(Ps_obj_tax_filt)`) of all samples
```{r}
#| label = "remove rare taxa",
#| cache = T
Prevalence_order_summary %>% 
  filter(`Sum prevalence` < (0.05 * nsamples(Ps_obj_tax_filt))) %>% 
  dplyr::select(Order) %>% 
  map(as.character) %>% 
  unlist() ->
  filterOrder

Ps_obj_order_prev_filt <- subset_taxa(Ps_obj_tax_filt, !Order %in% filterOrder)

sample_data(Ps_obj_order_prev_filt)$Library.size <- rowSums(otu_table(Ps_obj_order_prev_filt))
print(Ps_obj_tax_filt)
print(Ps_obj_order_prev_filt)
```

This removed `r ntaxa(Ps_obj_tax_filt) - ntaxa(Ps_obj_order_prev_filt)` or `r percent(1 - (ntaxa(Ps_obj_order_prev_filt) /  ntaxa(Ps_obj_tax_filt)))` of the ASVs, and `r percent(1 - (sum(otu_table(Ps_obj_order_prev_filt)) /  sum(otu_table(Ps_obj_tax_filt))), accuracy = 0.001)` of the reads.

Plot general prevalence features of the phyla
```{r}
#| label = "prevalence phylum",
#| cahce = T,
#| fig.height = 10,
#| fig.width = 10
# Subset to the remaining phyla
prevdf_phylum_filt <- subset(prevdf, 
                             Phylum %in% get_taxa_unique(Ps_obj_order_prev_filt, 
                                                         "Phylum"))
ggplot(prevdf_phylum_filt,
       aes(TotalAbundance, 
           Prevalence / nsamples(Ps_obj_order_prev_filt), 
           color = Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05,
             alpha = 0.5,
             linetype = 2) + 
  geom_point2(size = 2, alpha = 0.7) +
  scale_x_log10() +  
  xlab("Total Abundance") + 
  ylab("Prevalence [Frac. Samples]") +
  facet_wrap( ~ Phylum) + 
  theme(legend.position = "none")
```

Plot general prevalence features of the top 20 orders
```{r}
#| label = "prevalence order",
#| cache = T,
#| fig.height = 12,
#| fig.width = 10
# Subset to the remaining phyla
prevdf_order_filt <- subset(prevdf, 
                            Order %in% get_taxa_unique(Ps_obj_order_prev_filt, "Order"))

# grab the top 30 most abundant orders
prevdf_order_filt %>% 
  group_by(Order) %>%
  summarise(Combined.abundance = sum(TotalAbundance)) %>% 
  arrange(desc(Combined.abundance)) %>% 
  .[1:30, "Order"]  ->
  Orders2plot

prevdf_order_filt2 <- subset(prevdf,
                             Order %in% Orders2plot$Order)

ggplot(prevdf_order_filt2,
       aes(TotalAbundance,
           Prevalence / nsamples(Ps_obj_order_prev_filt), 
           color = Order)) +
# Include a guess for parameter
  geom_hline(yintercept = 0.05,
             alpha = 0.5,
             linetype = 2) + 
  geom_point2(size = 2, alpha = 0.7) +
  scale_x_log10() +  
  xlab("Total Abundance") +
  ylab("Prevalence [Frac. Samples]") +
  facet_wrap( ~ Order) + 
  theme(legend.position = "none")
```

#### Unsupervised filtering by prevalence
I'll remove all sequences which appear in less than `r `percent(prev_thresh)` of the samples
```{r}
#| label = "unsupervised prevalence filtering",
#| cache = T
# Define prevalence threshold as prev_thresh of total samples
prevalenceThreshold <- prev_thresh * nsamples(Ps_obj_order_prev_filt)
prevalenceThreshold

# Execute prevalence filter, using `prune_taxa()` function
keepTaxa <-
  row.names(prevdf_phylum_filt)[(prevdf_phylum_filt$Prevalence >= prevalenceThreshold)]
Ps_obj_seq_prev_filt <- prune_taxa(keepTaxa, Ps_obj_order_prev_filt)

sample_data(Ps_obj_seq_prev_filt)$Library.size <- rowSums(otu_table(Ps_obj_seq_prev_filt))
print(Ps_obj_order_prev_filt)
print(Ps_obj_seq_prev_filt)
```
This removed `r ntaxa(Ps_obj_order_prev_filt) - ntaxa(Ps_obj_seq_prev_filt)` or `r percent(1 - (ntaxa(Ps_obj_seq_prev_filt) /  ntaxa(Ps_obj_order_prev_filt)))` of the ASVs! 

However all these removed ASVs accounted for only: 
```{r} 
#| label = "iltering summary",
#| cache = T
prevdf_phylum_filt %>% 
  arrange(., Prevalence) %>% 
  group_by(Prevalence > prevalenceThreshold) %>% 
  summarise(Abundance = sum(TotalAbundance)) %>%
  mutate(`Rel. Ab.` = percent(Abundance / sum(Abundance), accuracy = 0.01)) %>% 
  kable(., digits = c(0, 1, 0)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```
So it's fine to remove them.

Test again the effect of library size and all other experimental factors on the community composition after filtering
```{r}
#| label = "mod abundance 2",
#| cache = T

frml2 <- as.formula(paste(
  "vegdist(otu_table(Ps_obj_SIP), method = 'bray')",
  paste("Library.size", Var2, Var3, paste0(Var2, ":", Var3), sep = " + "),
  sep = " ~ "
))

(mod2 <- adonis2(frml2,
  data = as(sample_data(Ps_obj_seq_prev_filt), "data.frame"),
  permutations = 999
))

plot_lib_dist(Ps_obj_seq_prev_filt)
plot_read_dist(Ps_obj_seq_prev_filt)
plot_mean_SD(Ps_obj_seq_prev_filt)
```

#### Save filtered phyloseq object
```{r}
#| label = "save phyloseq",
#| cache = T
saveRDS(Ps_obj_tax_filt, file = paste0(data_path, Proj_name, "_tax_filt.Rds"))
# save seqs
Ps_obj_tax_filt %>%  
  refseq() %>% 
  writeXStringSet(., filepath = paste0(data_path, "DADA2_reps_tax_filt.fa"), format = "fasta", width = 1000)

saveRDS(Ps_obj_order_prev_filt, file = paste0(data_path, Proj_name, "_tax_prev_filt.Rds"))
Ps_obj_order_prev_filt %>%  
  refseq() %>% 
  writeXStringSet(., filepath = paste0(data_path, "DADA2_reps_tax_prev_filt.fa"), format = "fasta", width = 1000)

saveRDS(Ps_obj_seq_prev_filt, file = paste0(data_path, Proj_name, "_seq_prev_filt.Rds"))
Ps_obj_seq_prev_filt %>%  
  refseq() %>% 
  writeXStringSet(., filepath = paste0(data_path, "DADA2_reps_seq_prev_filt.fa"), format = "fasta", width = 1000)

# save filtered seqtab
Ps_obj_seq_prev_filt %>% 
  t() %>%
  get_taxa() %>% 
  as_tibble(rownames = "ASV") %>%
  write_tsv(., 
            paste0(data_path, Proj_name, "_seqtab_seq_prev_filt.tsv"), 
            col_names = TRUE)

Ps_obj_seq_prev_filt %>% 
  t() %>% 
  tax_table() %>% 
  as_tibble() %>%
  rename(.otu = "ASV") %>% 
  write_tsv(., 
            paste0(data_path, Proj_name, "_taxa_silva_seq_prev_filt.tsv"), 
            col_names = TRUE)
```

```{r}
#| label = "colophon",
#| eval = T
sessioninfo::session_info() %>%
  details::details(
    summary = 'Current session info',
    open    = TRUE
  )
```

## References
